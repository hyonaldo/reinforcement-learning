{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 relu layer is added\n",
      "1 relu layer is added\n",
      "1 softmax layer is added\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "from __future__ import print_function\n",
    "import sys\n",
    "# from agents import *\n",
    "sys.path.append(\"/home1/gyrbsdl/jupyter_notebook/isearch/agent\")\n",
    "from agents_20171028 import *\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "### where path to read & write\n",
    "\n",
    "notebook_name = \"train_CartPole_deep\"\n",
    "BASE_DIR = './'\n",
    "CHECK_POINT_DIR = BASE_DIR+notebook_name\n",
    "TB_SUMMARY_DIR = CHECK_POINT_DIR+\"/tb_summary\"\n",
    "\n",
    "### what env to use ###\n",
    "\n",
    "import gym\n",
    "env = gym.make('CartPole-v0')\n",
    "\n",
    "state_space_size = 0\n",
    "\n",
    "try:\n",
    "    state_space_size = env.observation_space.n\n",
    "except:\n",
    "    state_space_size = env.observation_space.shape[0]\n",
    "action_space_size = env.action_space.n\n",
    "layers = [state_space_size, 16, 8, action_space_size]\n",
    "\n",
    "init_learning_rate = 1e-3\n",
    "min_learning_rate = 1e-7\n",
    "decay_learning_rate = 0.7\n",
    "previous_loss = 99999\n",
    "learning_frequency = 10\n",
    "agent = MultilayerPolicyGradient(learning_rate=init_learning_rate, discount_factor=0.99,\n",
    "                                 layers=layers, reward_standardize=True) #Load the agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./train_CartPole_deep removed\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "try:\n",
    "    shutil.rmtree(CHECK_POINT_DIR)\n",
    "    print CHECK_POINT_DIR, \"removed\"\n",
    "except:\n",
    "    print CHECK_POINT_DIR, \"does not exists yet\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_now():\n",
    "    import datetime\n",
    "    from dateutil.tz import tzlocal\n",
    "\n",
    "    # Get the current date/time with the timezone.\n",
    "    now = datetime.datetime.now(tzlocal())\n",
    "    fmt1 = now.strftime('%Y-%m-%d %A %H:%M:%S %Z')\n",
    "\n",
    "    # Print it out.\n",
    "    print 'now: %s' % (fmt1)\n",
    "    \n",
    "def try_and_error(env, agent, total_episodes,\n",
    "                  update_frequency, learning_rate_frequency, debug_frequency,\n",
    "                  is_train = True\n",
    "                 ):\n",
    "    total_reward = []\n",
    "    min_learning_rate = 1e-10\n",
    "    decay_learning_rate = 0.9\n",
    "    previous_loss = 9e+10\n",
    "    last_save_name = \"\"\n",
    "\n",
    "    for i in range(total_episodes):\n",
    "        s = env.reset()\n",
    "        reward_sum = 0\n",
    "        \n",
    "        done = False\n",
    "        while not done:\n",
    "            # Run the policy network and get an action to take.\n",
    "            if is_train == True:\n",
    "                action = agent.get_action(sess, s)\n",
    "            else:\n",
    "                action = agent.exploit(sess, s)\n",
    "            \n",
    "            # step the environment and get new measurements\n",
    "            observation, reward, done, _ = env.step(action)\n",
    "            reward_sum += reward\n",
    "            agent.after_action(sess, reward)\n",
    "            \n",
    "            s = observation\n",
    "        \n",
    "        if is_train == True:\n",
    "            loss , _ , _ = agent.after_episode(sess)\n",
    "            # If we have completed enough episodes, then update the policy network with our gradients.\n",
    "            if i % update_frequency == 0 and i != 0:\n",
    "                agent.after_batch(sess)\n",
    "\n",
    "            # decaying learning rate\n",
    "            if i % learning_rate_frequency == 0 and i != 0:\n",
    "                if (loss > previous_loss and agent.learning_rate >= min_learning_rate):\n",
    "                    agent.learning_rate = agent.learning_rate * decay_learning_rate\n",
    "                    print \"i:\", i, \"new agent.learning_rate\", agent.learning_rate\n",
    "                previous_loss = loss\n",
    "\n",
    "        total_reward.append(reward_sum)\n",
    "        \n",
    "        #Update our running tally of scores.\n",
    "        if i % debug_frequency == 0:\n",
    "            print \"-------------------------------------------\"\n",
    "            print_now()\n",
    "            mean = np.mean(total_reward)\n",
    "            print i, (mean)\n",
    "            plt_means.append(mean)\n",
    "            total_reward = []\n",
    "            if is_train == True and loss <= previous_loss:\n",
    "                # save only better model\n",
    "                agent.save_model(sess, CHECK_POINT_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "now: 2017-11-01 Wednesday 16:06:53 KST\n",
      "0 21.0\n",
      "('Model saved at', './train_CartPole_deep')\n",
      "i: 100 new agent.learning_rate 0.0009\n",
      "-------------------------------------------\n",
      "now: 2017-11-01 Wednesday 16:06:54 KST\n",
      "100 22.64\n",
      "('Model saved at', './train_CartPole_deep')\n",
      "i: 150 new agent.learning_rate 0.00081\n",
      "-------------------------------------------\n",
      "now: 2017-11-01 Wednesday 16:06:55 KST\n",
      "200 27.37\n",
      "('Model saved at', './train_CartPole_deep')\n",
      "i: 250 new agent.learning_rate 0.000729\n",
      "-------------------------------------------\n",
      "now: 2017-11-01 Wednesday 16:06:56 KST\n",
      "300 28.1\n",
      "('Model saved at', './train_CartPole_deep')\n",
      "i: 350 new agent.learning_rate 0.0006561\n",
      "-------------------------------------------\n",
      "now: 2017-11-01 Wednesday 16:06:58 KST\n",
      "400 26.31\n",
      "('Model saved at', './train_CartPole_deep')\n",
      "i: 450 new agent.learning_rate 0.00059049\n",
      "-------------------------------------------\n",
      "now: 2017-11-01 Wednesday 16:06:59 KST\n",
      "500 32.11\n",
      "('Model saved at', './train_CartPole_deep')\n",
      "i: 550 new agent.learning_rate 0.000531441\n",
      "-------------------------------------------\n",
      "now: 2017-11-01 Wednesday 16:07:01 KST\n",
      "600 42.22\n",
      "('Model saved at', './train_CartPole_deep')\n",
      "i: 700 new agent.learning_rate 0.0004782969\n",
      "-------------------------------------------\n",
      "now: 2017-11-01 Wednesday 16:07:03 KST\n",
      "700 48.79\n",
      "('Model saved at', './train_CartPole_deep')\n",
      "-------------------------------------------\n",
      "now: 2017-11-01 Wednesday 16:07:05 KST\n",
      "800 54.5\n",
      "('Model saved at', './train_CartPole_deep')\n",
      "i: 900 new agent.learning_rate 0.00043046721\n",
      "-------------------------------------------\n",
      "now: 2017-11-01 Wednesday 16:07:09 KST\n",
      "900 86.64\n",
      "('Model saved at', './train_CartPole_deep')\n"
     ]
    }
   ],
   "source": [
    "plt_means=[]\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "# Launch the tensorflow graph\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)  \n",
    "    agent.before(sess)\n",
    "    \n",
    "    try_and_error(env, agent,\n",
    "                  total_episodes=1000,\n",
    "                  update_frequency=3,\n",
    "                  debug_frequency=100,\n",
    "                  learning_rate_frequency=50,\n",
    "                  is_train=True\n",
    "                 )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Means of each bundle of episodes\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD8CAYAAABn919SAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nqQmDLklNGHRJauKPbmBooiLWqzEAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x39342d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now: 2017-11-01 Wednesday 16:07:14 KST\n"
     ]
    }
   ],
   "source": [
    "print(\"Means of each bundle of episodes\")\n",
    "plt.bar(range(len(plt_means)), plt_means, color=\"red\")\n",
    "plt.show()\n",
    "print_now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./train_CartPole_deep/model.ckpt\n",
      "('Model restored successfully from', './train_CartPole_deep')\n",
      "-------------------------------------------\n",
      "now: 2017-11-01 Wednesday 16:07:14 KST\n",
      "0 124.0\n",
      "('Model saved at', './train_CartPole_deep')\n",
      "-------------------------------------------\n",
      "now: 2017-11-01 Wednesday 16:07:19 KST\n",
      "100 126.3\n",
      "('Model saved at', './train_CartPole_deep')\n",
      "i: 200 new agent.learning_rate 0.000387420489\n",
      "-------------------------------------------\n",
      "now: 2017-11-01 Wednesday 16:07:25 KST\n",
      "200 139.86\n",
      "('Model saved at', './train_CartPole_deep')\n",
      "-------------------------------------------\n",
      "now: 2017-11-01 Wednesday 16:07:31 KST\n",
      "300 151.99\n",
      "('Model saved at', './train_CartPole_deep')\n",
      "i: 350 new agent.learning_rate 0.0003486784401\n",
      "-------------------------------------------\n",
      "now: 2017-11-01 Wednesday 16:07:37 KST\n",
      "400 176.2\n",
      "('Model saved at', './train_CartPole_deep')\n",
      "i: 450 new agent.learning_rate 0.00031381059609\n",
      "-------------------------------------------\n",
      "now: 2017-11-01 Wednesday 16:07:44 KST\n",
      "500 185.94\n",
      "('Model saved at', './train_CartPole_deep')\n",
      "i: 550 new agent.learning_rate 0.000282429536481\n",
      "i: 600 new agent.learning_rate 0.000254186582833\n",
      "-------------------------------------------\n",
      "now: 2017-11-01 Wednesday 16:07:51 KST\n",
      "600 186.83\n",
      "('Model saved at', './train_CartPole_deep')\n",
      "i: 700 new agent.learning_rate 0.00022876792455\n",
      "-------------------------------------------\n",
      "now: 2017-11-01 Wednesday 16:07:58 KST\n",
      "700 184.55\n",
      "('Model saved at', './train_CartPole_deep')\n",
      "i: 800 new agent.learning_rate 0.000205891132095\n",
      "-------------------------------------------\n",
      "now: 2017-11-01 Wednesday 16:08:05 KST\n",
      "800 188.24\n",
      "('Model saved at', './train_CartPole_deep')\n",
      "i: 900 new agent.learning_rate 0.000185302018885\n",
      "-------------------------------------------\n",
      "now: 2017-11-01 Wednesday 16:08:11 KST\n",
      "900 181.12\n",
      "('Model saved at', './train_CartPole_deep')\n",
      "now: 2017-11-01 Wednesday 16:08:18 KST\n"
     ]
    }
   ],
   "source": [
    "########## 기존 모델을 로딩하여 추가로 학습 후 저장하기 ##########\n",
    "\n",
    "# Launch the tensorflow graph\n",
    "with tf.Session() as sess:\n",
    "    \n",
    "    agent.load_model(sess, CHECK_POINT_DIR)\n",
    "    \n",
    "    try_and_error(env, agent,\n",
    "                  total_episodes=1000,\n",
    "                  update_frequency=3,\n",
    "                  debug_frequency=100,\n",
    "                  learning_rate_frequency=50,\n",
    "                  is_train=True\n",
    "                 )\n",
    "    \n",
    "\n",
    "print_now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./train_CartPole_deep/model.ckpt\n",
      "('Model restored successfully from', './train_CartPole_deep')\n",
      "-------------------------------------------\n",
      "now: 2017-11-01 Wednesday 16:08:18 KST\n",
      "0 200.0\n",
      "-------------------------------------------\n",
      "now: 2017-11-01 Wednesday 16:08:24 KST\n",
      "100 200.0\n",
      "-------------------------------------------\n",
      "now: 2017-11-01 Wednesday 16:08:30 KST\n",
      "200 200.0\n",
      "-------------------------------------------\n",
      "now: 2017-11-01 Wednesday 16:08:36 KST\n",
      "300 200.0\n",
      "-------------------------------------------\n",
      "now: 2017-11-01 Wednesday 16:08:42 KST\n",
      "400 200.0\n",
      "-------------------------------------------\n",
      "now: 2017-11-01 Wednesday 16:08:49 KST\n",
      "500 200.0\n",
      "-------------------------------------------\n",
      "now: 2017-11-01 Wednesday 16:08:55 KST\n",
      "600 200.0\n",
      "-------------------------------------------\n",
      "now: 2017-11-01 Wednesday 16:09:01 KST\n",
      "700 200.0\n",
      "-------------------------------------------\n",
      "now: 2017-11-01 Wednesday 16:09:07 KST\n",
      "800 200.0\n",
      "-------------------------------------------\n",
      "now: 2017-11-01 Wednesday 16:09:13 KST\n",
      "900 200.0\n"
     ]
    }
   ],
   "source": [
    "########## 기존 모델을 이용하기만 해보기 ##########\n",
    "\n",
    "# Launch the tensorflow graph\n",
    "with tf.Session() as sess:\n",
    "    agent.load_model(sess, CHECK_POINT_DIR)\n",
    "    agent.before(sess)\n",
    "    \n",
    "    try_and_error(env, agent,\n",
    "                  total_episodes=1000,\n",
    "                  update_frequency=3,\n",
    "                  debug_frequency=100,\n",
    "                  learning_rate_frequency=50,\n",
    "                  is_train=False\n",
    "                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Means of each bundle of episodes\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7084dd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now: 2017-11-01 Wednesday 16:09:19 KST\n"
     ]
    }
   ],
   "source": [
    "print(\"Means of each bundle of episodes\")\n",
    "plt.bar(range(len(plt_means)), plt_means, color=\"red\")\n",
    "plt.show()\n",
    "print_now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./train_CartPole_deep\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['MultilayerPolicyGradient/MultilayerPolicyGradient/W2/Adam',\n",
       " 'MultilayerPolicyGradient/MultilayerPolicyGradient/W1/Adam',\n",
       " 'MultilayerPolicyGradient/Variable',\n",
       " 'MultilayerPolicyGradient/MultilayerPolicyGradient/W1/Adam_1',\n",
       " 'MultilayerPolicyGradient/Variable_1',\n",
       " 'MultilayerPolicyGradient/MultilayerPolicyGradient/W0/Adam',\n",
       " 'MultilayerPolicyGradient/Variable_2',\n",
       " 'MultilayerPolicyGradient/MultilayerPolicyGradient/W0/Adam_1',\n",
       " 'MultilayerPolicyGradient_1/beta2_power',\n",
       " 'MultilayerPolicyGradient/MultilayerPolicyGradient/Variable_2/Adam_1',\n",
       " 'MultilayerPolicyGradient/MultilayerPolicyGradient/Variable_2/Adam',\n",
       " 'MultilayerPolicyGradient/MultilayerPolicyGradient/W2/Adam_1',\n",
       " 'MultilayerPolicyGradient/MultilayerPolicyGradient/Variable_1/Adam_1',\n",
       " 'MultilayerPolicyGradient/MultilayerPolicyGradient/Variable/Adam_1',\n",
       " 'MultilayerPolicyGradient/MultilayerPolicyGradient/Variable_1/Adam',\n",
       " 'MultilayerPolicyGradient_1/beta1_power',\n",
       " 'MultilayerPolicyGradient/MultilayerPolicyGradient/Variable/Adam',\n",
       " 'MultilayerPolicyGradient/W1',\n",
       " 'MultilayerPolicyGradient/W0',\n",
       " 'MultilayerPolicyGradient/W2']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print CHECK_POINT_DIR \n",
    "agent.read_ckpt(CHECK_POINT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
